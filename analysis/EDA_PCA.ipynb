{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis (EDA) performed on data collected during 2016 and quality evaluated manually by experts.  \n",
    "Each data point (row) corresponds to one run (= up to 8-12 h of data collecting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# LOAD\n",
    "\n",
    "load modules and the data  \n",
    "perform first steps of preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "load modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "read data from files:\n",
    "* data.csv                             -- data\n",
    "* runs_2016_TPC_GOOD_Tracking.dat -- list of runs with good tracking\n",
    "* runs_2016_TPC_GOOD_HadronID.dat -- list of runs with good PID\n",
    "* sensitive_variables_list.csv           -- list of variables which are important in QA acording to experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('data-2016-run-level/data.csv', index_col=False)  # index_col=False due to commas at the end of each line\n",
    "df_orig.columns = [c.replace('/I', '').replace('/D','').replace('\\n','') for c in df_orig.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Print sensitive variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('data-2016-run-level/sensitive_variables_list.csv') as f:\n",
    "    sensitive_variables = f.readlines()[0].split(':')\n",
    "sensitive_variables = [sv.replace('/D', '').replace('/I', '').replace('\\n', '') for sv in sensitive_variables]\n",
    "print('\\n'.join(sensitive_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "good_runs_files = {'track':'data-2016-run-level/runs_2016_TPC_GOOD_Tracking.dat', \n",
    "                   'PID':'data-2016-run-level/runs_2016_TPC_GOOD_HadronID.dat'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(good_runs_files['track']) as f:\n",
    "    good_trk = [int(line.replace(',\\n', '')) for line in f.readlines()]\n",
    "with open(good_runs_files['PID']) as f:\n",
    "    good_pid = [int(line.replace(',\\n', '')) for line in f.readlines()]\n",
    "    \n",
    "trk_only, pid_only, both, none = [],[],[],[]\n",
    "for run in df_orig['run']:\n",
    "    intrk, inpid = run in good_trk, run in good_pid\n",
    "    if     intrk and     inpid:   both.append(run)\n",
    "    if     intrk and not inpid:   trk_only.append(run)\n",
    "    if not intrk and     inpid:   pid_only.append(run)\n",
    "    if not intrk and not inpid:   none.append(run)\n",
    "print(f'There are N runs for which good are/is:\\n'\n",
    "      f'tracking only = {len(trk_only)}\\n'\n",
    "      f'pid only = {len(pid_only)}\\n'\n",
    "      f'both = {len(both)}\\n'\n",
    "      f'none = {len(none)}')\n",
    "print()\n",
    "print(f'good tracking & bad PID runs:\\n {trk_only}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are only 8 runs with good tracking and bad PID.  \n",
    "__For further analysis use only runs with consistently good/bad tracking & PID__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "good_runs = both\n",
    "bad_runs = none\n",
    "print(good_runs[:10], f'... -> {len(good_runs)} good runs')\n",
    "print(bad_runs[:10], f'... -> {len(bad_runs)} bad runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sens = df_orig.drop([c for c in df_orig.columns if c not in (sensitive_variables+['run', ]) ], axis=1)\n",
    "df_sens = df_sens[[run in good_runs or run in bad_runs for run in df_sens['run']]]\n",
    "df_sens['good'] = [1 if run in good_runs else 0 for run in df_sens['run']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS OF SENSITIVE VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D analysis of sensitive variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 50)\n",
    "df_sens.describe()\n",
    "# pd.reset_option('max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens.query('good==1').describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens.query('good==0').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D histograms\n",
    "\n",
    "plot 1D histograms for: whole range (left) and quantiles: unnormalized (center) and normalized per class (right)  \n",
    "vertical dashed lines denotes quentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for var in df_sens.columns:\n",
    "#     if var == 'good': continue\n",
    "\n",
    "\n",
    "def plot_hist1D(var, n_bins, q_low, q_high):\n",
    "    quantiles = [q_low, q_high]\n",
    "    var_good = df_sens.query('good==1')[var].tolist()\n",
    "    var_bad  = df_sens.query('good==0')[var].tolist()\n",
    "\n",
    "    plt.figure()\n",
    "    fig, axes = plt.subplots(1,3, figsize=(18,5))\n",
    "    for i in range(3):\n",
    "        qs = [0,1] if not i else quantiles\n",
    "        quantile_vals = np.quantile(var_good+var_bad, qs)\n",
    "        _, bins = np.histogram(var_good + var_bad, bins=n_bins, range=quantile_vals)\n",
    "        normed = (i == 2)\n",
    "        axes[i].hist(var_good, bins=bins, alpha=1, color='blue', linewidth=1.2, histtype='step', linestyle='-', density=normed)\n",
    "        axes[i].hist(var_bad, bins=bins, alpha=1, edgecolor='red', linewidth=2, histtype='step', density=normed)\n",
    "\n",
    "\n",
    "        for qv in quantile_vals: \n",
    "            axes[0].axvline(qv, linestyle='--', color='k')\n",
    "            axes[0].text()\n",
    "        axes[0].set_title('whole range')\n",
    "        axes[1].set_title(f'limited range (q={quantiles[0]*100:.0f},{quantiles[1]*100:.0f}): {quantile_vals[0]:.3f}, {quantile_vals[1]:.3f}')\n",
    "        axes[2].set_title('normalized per class')\n",
    "\n",
    "        plt.suptitle(var)\n",
    "\n",
    "#w_nbins = interactive(lambda n: n, n=(3,100,1));\n",
    "#display(w_nbins)\n",
    "#print(w_nbins.kwargs)\n",
    "#w_varname.observe(update_x_range, 'value')\n",
    "\n",
    "plt.text?\n",
    "\n",
    "wg_colname = widgets.Dropdown(description='column name', options=df_sens.columns)\n",
    "wg_nbins = widgets.IntSlider(description='n bins', min=3, max=100, value=20, step=1, continuous_update=False)\n",
    "wg_qlow = widgets.FloatSlider(description='lower quantile', min=0, max=0.3, value=0.05, step=0.01, continuous_update=False)\n",
    "wg_qhigh = widgets.FloatSlider(description='upper quantile', min=0.7, max=1, value=0.95, step=0.01, continuous_update=False)\n",
    "\n",
    "def make_plot(name, n_bins):\n",
    "    print('making plot of {} with {} bins'.format(name, n_bins))\n",
    "ui = widgets.HBox([wg_colname, wg_nbins])\n",
    "ui2 = widgets.HBox([wg_qlow, wg_qhigh])\n",
    "\n",
    "out = widgets.interactive_output(plot_hist1D, {'var': wg_colname, 'n_bins': wg_nbins, 'q_low':wg_qlow, 'q_high':wg_qhigh})\n",
    "display(ui2)\n",
    "display(ui, out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#w_varname = interactive(plot_hist1D, var=df_sens.columns, n_bins=(3,100,1), quantiles=fixed([0.01, 0.99]), continous_update=False);\n",
    "#w_qlow = interactive(lambda q: q, q=(0.0, 0.5, 0.01));\n",
    "#w_qhigh = interactive(lambda q: q, q=(0.5, 1.0, 0.01));\n",
    "\n",
    "#display(w_varname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "quantiles = [0.05, 0.95]\n",
    "n_bins = 25\n",
    "\n",
    "for var in df_sens.columns:\n",
    "    if var == 'good': continue\n",
    "    var_good = df_sens.query('good==1')[var].tolist()\n",
    "    var_bad  = df_sens.query('good==0')[var].tolist()\n",
    "    \n",
    "    plt.figure()\n",
    "    fig, axes = plt.subplots(1,3, figsize=(18,5))\n",
    "    for i in range(3):\n",
    "        qs = [0,1] if not i else quantiles\n",
    "        quantile_vals = np.quantile(var_good+var_bad, qs)\n",
    "        _, bins = np.histogram(var_good + var_bad, bins=n_bins, range=quantile_vals)\n",
    "        normed = (i == 2)\n",
    "        axes[i].hist(var_good, bins=bins, alpha=1, color='blue', linewidth=1.2, histtype='step', linestyle='-', density=normed)\n",
    "        axes[i].hist(var_bad, bins=bins, alpha=1, edgecolor='red', linewidth=2, histtype='step', density=normed)\n",
    "        \n",
    "        \n",
    "    for qv in quantile_vals: axes[0].axvline(qv, linestyle='--', color='k')\n",
    "    axes[0].set_title('whole range')\n",
    "    axes[1].set_title(f'limited range (q={quantiles[0]*100:.0f},{quantiles[1]*100:.0f}): {quantile_vals[0]:.3f}, {quantile_vals[1]:.3f}')\n",
    "    axes[2].set_title('normalized')\n",
    "        \n",
    "    plt.suptitle(var)\n",
    "\n",
    "#     sns.distplot(var_good, kde=False)\n",
    "#     sns.distplot(var_bad, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Partial conlusions\n",
    "There are not so many distinctive variables, some of most promising:\n",
    "* __meanTPCnclF__ (mean no. TPC clusters findable fraction, i.e. after subtraction of points crossing installation frames etc) - bad runs have much higher variance, note that some bad runs are beyond central quantiles\n",
    "* __meanTPCChi2__ and __meanTPCncl__ - same as above\n",
    "* __offsetdRC__ - bad runs are shifted towards lower values and have higher variance\n",
    "* __meanMult/Pos/Neg__ - bad runs are a bit wider and shifted\n",
    "* __iroc/oroc_\\*__ - takes only 2 values (17 or 18) but 17 appears only for bad runs (without exceptions), in around 15-35% cases\n",
    "* __MIPattachSlopeA/C__, __tpcitsMatchA__, __y/lambdaPull(HighPt)__ - substantial amount of bad runs is outside of central quantiles\n",
    "\n",
    "Also:  \n",
    "__meanVertX/Y__ - (almost) all runs have the same values - they will be removed from further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sens = df_sens.drop(['meanVertX', 'meanVertY'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "colors = ['#F53E22', '#3E22F5']\n",
    "pal = sns.color_palette(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# --  BEAUTIFUL PANDAS TABLE  --\n",
    "# ------------------------------\n",
    "# cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)\n",
    "\n",
    "# def magnify():\n",
    "#     return [dict(selector=\"th\",\n",
    "#                  props=[(\"font-size\", \"7pt\")]),\n",
    "#             dict(selector=\"td\",\n",
    "#                  props=[('padding', \"0em 0em\")]),\n",
    "#             dict(selector=\"th:hover\",\n",
    "#                  props=[(\"font-size\", \"12pt\")]),\n",
    "#             dict(selector=\"tr:hover td:hover\",\n",
    "#                  props=[('max-width', '200px'),\n",
    "#                         ('font-size', '15pt')])\n",
    "# ]\n",
    "\n",
    "# corr.style.background_gradient(cmap, axis=1)\\\n",
    "#     .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n",
    "#     .set_caption(\"Hover to magify\")\\\n",
    "#     .set_precision(2)\\\n",
    "#     .set_table_styles(magnify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_sens.corr()\n",
    "\n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot(111)\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns,\n",
    "        cbar=1, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.85\n",
    "\n",
    "print(f'Variable pairs with corr. coef > {threshold}:')\n",
    "print('- -'*19)\n",
    "n_above_th = 0\n",
    "for c1 in corr.columns:\n",
    "    for c2 in corr.columns:\n",
    "        if corr.columns.tolist().index(c1) == corr.columns.tolist().index(c2): continue\n",
    "        val = corr[c1][c2]\n",
    "        if abs(val) > threshold:\n",
    "            print (f'{c1:20s} : {c2:20s}: {val:6.2f}\\t:')\n",
    "            n_above_th += 1 #\n",
    "print('- -'*19)\n",
    "print(f'There are {int(n_above_th/2)} variable pairs with corr > {threshold}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Partial conculsions\n",
    "<a id='correlated_sets'></a>\n",
    "\n",
    "One can find several sets of highly correlated variables:  \n",
    "{meanMult - meanMultPos - meanMultNeg } -- tpcMatch* -- {meanTPCnclF - meanTPCncl -- meanTPCChi2}   \n",
    "{offsetdZA - offsetZC - zPull(HighPt)}  \n",
    "{ptPull(HighPt) - lambdaPull(HighPt)} -- MIPattachSlopeA  \n",
    "{zPull(HighPt) - offsetdZA}  \n",
    "{resolutionMIP(ele)}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "n_components = 20\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import decomposition\n",
    "\n",
    "X = df_sens.drop(['good', 'run'], axis=1)\n",
    "y = df_sens['good']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "df_sens_scaled = pd.DataFrame(X)\n",
    "df_sens_scaled.columns = df_sens.drop(['good', 'run'], axis=1).columns\n",
    "\n",
    "pca = decomposition.PCA(n_components=n_components)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)\n",
    "X_good = X[y==1,:]\n",
    "X_bad  = X[y==0,:]\n",
    "\n",
    "data_dict = {'good':y}\n",
    "for c in range(n_components):\n",
    "    data_dict['PCA'+str(c)] = X[:,c]\n",
    "df_pca = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check variance explained with consecutive components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pca.explained_variance_ratio_.cumsum()\n",
    "plt.plot(range(n_components), Y, 'bo-')\n",
    "plt.ylabel('Explained variance')\n",
    "plt.xlabel('PCA components')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again correlation plot, but including PCA components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "df_sens_plus_pca = pd.concat([df_sens_scaled, df_pca], axis=1)\n",
    "corr = df_sens_plus_pca.corr()\n",
    "\n",
    "fig = plt.figure(figsize=(15,12))\n",
    "ax = fig.add_subplot(111)\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns,\n",
    "        cbar=1, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "plt.cla()\n",
    "\n",
    "# # for name, label in [('Bad', 0), ('Good', 1)]:\n",
    "# #     ax.text3D(X[y == label, 0].mean(),\n",
    "# #               X[y == label, 1].mean() + 1.5,\n",
    "# #               X[y == label, 2].mean(), name,\n",
    "# #               horizontalalignment='center',\n",
    "# #               bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))\n",
    "# # Reorder the labels to have colors matching the cluster results\n",
    "\n",
    "ax.scatter(X_bad[:, 0], X_bad[:, 1], X_bad[:, 2], c='r',edgecolor='k')\n",
    "ax.scatter(X_good[:, 0], X_good[:, 1], X_good[:, 2], c='b',edgecolor='k')\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "ax.set_xlabel('PCA 0')\n",
    "ax.set_ylabel('PCA 1')\n",
    "ax.set_zlabel('PCA 2')\n",
    "\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "n_comp = 4\n",
    "\n",
    "fig, axes = plt.subplots(1,n_comp, figsize=(15,4))\n",
    "\n",
    "for i in range(n_comp):\n",
    "    _, bins = np.histogram(list(X_good[:,i])+list(X_bad[:,i]), bins=50)\n",
    "    normed = 1\n",
    "    axes[i].hist(X_good[:,i], bins=bins, alpha=1, color='blue', linewidth=1.2, histtype='step', linestyle='-', density=normed)\n",
    "    axes[i].hist(X_bad[:,i], bins=bins, alpha=1, edgecolor='red', linewidth=2, histtype='step', density=normed)\n",
    "    axes[i].set_title('PCA'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find variables most correlated with selected variable and their 2D distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "min_n_vars = 4  # includes autocorr\n",
    "n_pca = 20\n",
    "\n",
    "for pca_comp in range(n_pca):\n",
    "    selected_var = 'PCA'+str(pca_comp)\n",
    "     # can be (0,1) or integer\n",
    "    var_lst = corr[selected_var][abs(corr[selected_var]) > threshold].index.tolist()\n",
    "    if len(var_lst) < min_n_vars: var_lst = abs(corr[selected_var]).sort_values(ascending=False)[:min_n_vars].index.tolist()\n",
    "    vars_corrs = sorted(\n",
    "        [(var, corr[selected_var][var]) for var in var_lst], \n",
    "        key=lambda x: -abs(x[1])\n",
    "    )\n",
    "    vars_corrs_str = '\\n\\t'.join([f'{v}({c:.2f})' for v,c in vars_corrs[1:]])\n",
    "    print(f'Variables most correlated with {selected_var}:\\n\\t{vars_corrs_str}')\n",
    "#     for var in var_lst:\n",
    "#         print(f'{var:20s}: {corr[selected_var][var]:6.2f}')\n",
    "#     print(f'There are {len(var_lst)} such variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "selected_var = 'lambdaPull'\n",
    "threshold = 5 # can be (0,1) or integer\n",
    "if threshold < 1:\n",
    "    # corr. coef. value threshold\n",
    "    var_lst = corr[selected_var][abs(corr[selected_var]) > threshold].index.tolist()\n",
    "else:\n",
    "    # no. variables threshold\n",
    "    var_lst = abs(corr[selected_var]).sort_values(ascending=False)[:threshold].index.tolist()\n",
    "    \n",
    "print(f'Variables most correlated with {selected_var}: ')\n",
    "for var in var_lst:\n",
    "    print(f'{var:20s}: {corr[selected_var][var]:6.2f}')\n",
    "print(f'There are {len(var_lst)} such variables')\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "# g = sns.pairplot(df_sens_plus_pca, hue='good', vars=[c for c in df_pca.columns if 'PCA' in c], palette=pal, markers=['x', 'o'])\n",
    "g = sns.pairplot(df_sens_plus_pca, hue='good', hue_order=[0,1], vars=var_lst, \n",
    "                 palette=pal, markers=['x', 'o'], plot_kws=dict(s=20, alpha=1)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Partial conclusions\n",
    "\n",
    "Keeping 5, 10 and 15 first PCA component explains 65%, 80%, 90% respectively\n",
    "\n",
    "Significant number of variables could be removed without losing too much information -- but not necessarly replaced with PCA, e.g. correlation between PCA0 and its most correlated variables is 0.6-0.5 while between those variables 0.98-0.8.\n",
    "\n",
    "Variables most correlated with consecutive PCA components create clusters which partially correspond to sets from \n",
    "[correlation check](#correlated_sets)\n",
    "\n",
    "Some variables (e.g. PCA0) despite being highly disciminative are weakly correlated with goodness of run - commonly bad runs are frequently distributed just more widely than good ones  \n",
    "One may think about creating simple metric which would tell how discriminative is a variable, like accuracy decision tree with max depth = 2 or 4 (2 is enough to select central peak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test removing most correlated features\n",
    "\n",
    "* NSigmasClf: \n",
    "    * simple product of n_sigmas of each variable\n",
    "    * product of n_sigmas where n_sigma = 1 if n_sigma < 2,3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
