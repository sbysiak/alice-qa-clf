{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import adadelta\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "from helper import ae_errors\n",
    "from helper.utilis import show_qa_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "style = \"\"\"\n",
    "<style>\n",
    "div.output_area {\n",
    "    overflow-y: scroll;\n",
    "}\n",
    "div.output_area img {\n",
    "    max-width: unset;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "def make_cell_scrollable():\n",
    "    HTML(style)\n",
    "    \n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_orig = pd.read_csv('data/trending_merged_LHC18q_withGraphs.csv')\n",
    "\n",
    "target_col = 'alias_global_Warning'\n",
    "#----------\n",
    "df = df_orig[[c for c in df_orig.columns if \n",
    "              ('gr' not in c and 'alias' not in c and 'Unnamed' not in c)\n",
    "              and c != 'dataType.fString'\n",
    "              or c == target_col\n",
    "             ]]\n",
    "rename = lambda c: c if c != target_col else 'bad'\n",
    "df.columns = [rename(c) for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()\n",
    "nonphysical_cols = ['run', 'chunkID', 'time', \n",
    "                   'year', 'period.fString', 'pass.fString', 'runType.fString', \n",
    "                   'startTimeGRP', 'stopTimeGRP', 'duration', \n",
    "                   'iroc_A_side', 'oroc_A_side', 'iroc_C_side', 'oroc_C_side',\n",
    "                   'chunkStart', 'chunkStop', 'chunkMean', 'chunkMedian', 'chunkRMS', 'chunkDuration']\n",
    "\n",
    "no_variance_cols = df.std()[(df.std() < 1e-6).tolist()].index.tolist()\n",
    "cols_exclude = nonphysical_cols + no_variance_cols\n",
    "\n",
    "for c in df.columns:\n",
    "    if c not in cols_exclude:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df[[c for c in df.columns if c not in cols_exclude]].drop('bad', axis=1)\n",
    "\n",
    "for i in range(5):\n",
    "    input_data[f'random{i}'] = np.random.randn(len(input_data))\n",
    "\n",
    "x = input_data.to_numpy()\n",
    "y = df['bad'].to_numpy()\n",
    "\n",
    "x_test_bad = x[y == 1]\n",
    "x_train_val_good, x_test_good = train_test_split(x[y == 0], test_size=0.1)  \n",
    "x_train, x_val = train_test_split(x_train_val_good, test_size=0.1)  # x_val are GOOD samples used to monitor overfitting\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# scaler = MaxAbsScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train     = scaler.transform(x_train)\n",
    "x_val       = scaler.transform(x_val)\n",
    "x_test_good = scaler.transform(x_test_good)\n",
    "x_test_bad  = scaler.transform(x_test_bad)\n",
    "x_all       = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0.6, 1, 30)\n",
    "plt.hist(df_orig.query('alias_global_Warning == 1')['tpcItsMatchHighPtA'], histtype='step', color='r', bins=bins, density=1)\n",
    "plt.hist(df_orig.query('alias_global_Outlier == 1')['tpcItsMatchHighPtA'], histtype='step', color='k', bins=bins, density=1)\n",
    "plt.hist(df_orig.query('alias_global_Warning == 0')['tpcItsMatchHighPtA'], histtype='step', color='blue', bins=bins, density=1)\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InteractionRate viz. and binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_y = 1000\n",
    "#-------------\n",
    "plt.figure(figsize=(25,5))\n",
    "# plt.plot(df['chunkMean'], df['interactionRate']+np.random.random(len(df))*jitter_y, '.', ms=3)\n",
    "plt.plot(df.query('bad == 0')['chunkMean'], df.query('bad == 0')['interactionRate']+np.random.random(len(df.query('bad == 0')))*jitter_y, '.', ms=2, color='b')\n",
    "plt.plot(df.query('bad == 1')['chunkMean'], df.query('bad == 1')['interactionRate']+np.random.random(len(df.query('bad == 1')))*jitter_y, '.', ms=8, marker='x', color='r')\n",
    "plt.xlabel('chunk mean time');\n",
    "plt.ylabel('interactionRate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(df.query('bad == 0')['interactionRate'], bins=20, histtype='step', color='b', density=1)\n",
    "# plt.hist(df.query('bad == 1')['interactionRate'], bins=20, histtype='step', color='r', density=1)\n",
    "\n",
    "plt.hist(df['interactionRate'], bins=50, histtype='step', color='b', density=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Division into 3/5 interaction rate bins:  \n",
    "5 bins: (0-2),(2-4),(4-6),(6-7),(7-8)k  \n",
    "3 bins: (0-4),(4-7),(7-8)k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_irate_bin3(row):\n",
    "    irate_val = row['interactionRate']\n",
    "    if irate_val < 4000:\n",
    "        return 1\n",
    "    if irate_val > 4000 and irate_val < 7000: \n",
    "        return 2\n",
    "    if irate_val > 7000:\n",
    "        return 3\n",
    "    \n",
    "def assign_irate_bin5(row):\n",
    "    irate_val = row['interactionRate']\n",
    "    if irate_val < 2000:\n",
    "        return 1\n",
    "    if irate_val > 2000 and irate_val < 4000: \n",
    "        return 2\n",
    "    if irate_val > 4000 and irate_val < 6000: \n",
    "        return 3\n",
    "    if irate_val > 6000 and irate_val < 7000: \n",
    "        return 4\n",
    "    if irate_val > 7000:\n",
    "        return 5\n",
    "\n",
    "df['irate_bin3'] = df.apply(assign_irate_bin3, axis=1)\n",
    "df['irate_bin5'] = df.apply(assign_irate_bin5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    print(f'bin {i}/3: {df[\"irate_bin3\"].value_counts(sort=False)[i]}')\n",
    "print()\n",
    "for i in range(1,6):\n",
    "    print(f'bin {i}/5: {df[\"irate_bin5\"].value_counts(sort=False)[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irate_bin_31 = df.query('irate_bin3 == 1').index\n",
    "irate_bin_32 = df.query('irate_bin3 == 2').index\n",
    "irate_bin_33 = df.query('irate_bin3 == 3').index\n",
    "\n",
    "irate_bin_51 = df.query('irate_bin5 == 1').index\n",
    "irate_bin_52 = df.query('irate_bin5 == 2').index\n",
    "irate_bin_53 = df.query('irate_bin5 == 3').index\n",
    "irate_bin_54 = df.query('irate_bin5 == 4').index\n",
    "irate_bin_55 = df.query('irate_bin5 == 5').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# irate_bin_31 = df.query('interactionRate < 4000').index   # indices of instances from interactionRate bin 1 out of 3\n",
    "# irate_bin_32 = df.query('interactionRate > 4000 & interactionRate < 7000 ').index\n",
    "# irate_bin_33 = df.query('interactionRate > 7000 ').index\n",
    "\n",
    "# print(f'Counts per bin:\\n1/3: {len(irate_bin_31)}\\n2/3: {len(irate_bin_32)}\\n3/3: {len(irate_bin_33)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# irate_bin_51 = df.query('interactionRate < 2000').index   # indices of instances from interactionRate bin 1 out of 5\n",
    "# irate_bin_52 = df.query('interactionRate > 2000 & interactionRate < 4000 ').index\n",
    "# irate_bin_53 = df.query('interactionRate > 4000 & interactionRate < 6000 ').index\n",
    "# irate_bin_54 = df.query('interactionRate > 6000 & interactionRate < 7000 ').index\n",
    "# irate_bin_55 = df.query('interactionRate > 7000 ').index\n",
    "\n",
    "# print(f'Counts per bin:\\n1/5: {len(irate_bin_51)}\\n2/5: {len(irate_bin_52)}\\n3/5: {len(irate_bin_53)}\\n4/5: {len(irate_bin_54)}\\n5/5: {len(irate_bin_55)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = x_train.shape[1]\n",
    "coding_layers_sizes = [64,32]\n",
    "bottleneck_size = 16\n",
    "\n",
    "ae_input = Input(shape=(input_size,))\n",
    "encoded = Dense(coding_layers_sizes[0], activation='relu')(ae_input)\n",
    "for lsize in coding_layers_sizes[1:]:\n",
    "    encoded = Dense(lsize, activation='relu')(encoded)\n",
    "#     encoded = Dropout(0.2)(encoded)\n",
    "encoded = Dense(bottleneck_size, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(coding_layers_sizes[-1], activation='relu')(encoded)\n",
    "for lsize in reversed(coding_layers_sizes[:-1]):\n",
    "    decoded = Dense(lsize, activation='relu')(decoded)\n",
    "decoded = Dense(input_size, activation='linear')(decoded)\n",
    "\n",
    "autoencoder = Model(ae_input, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(ae_input, decoded)\n",
    "autoencoder.compile(optimizer=adadelta(lr=0.2), loss='mean_squared_error')\n",
    "\n",
    "fit = autoencoder.fit(x_train, x_train, \n",
    "                epochs=20,\n",
    "                batch_size=32,\n",
    "                verbose=2,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, x_val),\n",
    "                callbacks=[PlotLossesKeras()])\n",
    "PlotLossesKeras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = fit.history['loss']\n",
    "val_loss = fit.history['val_loss']\n",
    "epochs = fit.epoch\n",
    "\n",
    "plt.plot(epochs, loss, 'bx--', label='train loss', color='blue')\n",
    "plt.plot(epochs, val_loss, 'rx--', label='val loss', color='green')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute predictions and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred_train     = autoencoder.predict(x_train)\n",
    "x_pred_val       = autoencoder.predict(x_val)\n",
    "x_pred_test_good = autoencoder.predict(x_test_good)\n",
    "x_pred_test_bad  = autoencoder.predict(x_test_bad)\n",
    "x_pred_all       = autoencoder.predict(x_all)\n",
    "\n",
    "mse_train     = mean_squared_error(x_train, x_pred_train)\n",
    "mse_val       = mean_squared_error(x_val, x_pred_val)\n",
    "mse_test_good = mean_squared_error(x_test_good, x_pred_test_good)\n",
    "mse_test_bad  = mean_squared_error(x_test_bad, x_pred_test_bad)\n",
    "mse_all       = mean_squared_error(x_all, x_pred_all)\n",
    "\n",
    "print(f'average MSE:\\n\\t all = {mse_all:.3f}\\n\\t {\"-\"*10}\\n\\t train = {mse_train:.3f}\\n\\t val = {mse_val:.3f}\\n\\t test_good = {mse_test_good:.3f}\\n\\t test_bad = {mse_test_bad:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_distr_train     = ((x_train - x_pred_train)**2).mean(axis=1)\n",
    "mse_distr_val       = ((x_val - x_pred_val)**2).mean(axis=1)\n",
    "mse_distr_test_good = ((x_test_good - x_pred_test_good)**2).mean(axis=1)\n",
    "mse_distr_test_bad  = ((x_test_bad - x_pred_test_bad)**2).mean(axis=1)\n",
    "mse_distr_all       = ((x_all - x_pred_all)**2).mean(axis=1)\n",
    "\n",
    "# plot histos\n",
    "bins = np.linspace(np.quantile(np.log10(mse_distr_all), 0), np.quantile(np.log10(mse_distr_all), 1), 20)\n",
    "plt.hist(np.log10(mse_distr_train), bins=bins, density=1, lw=2, ls='-.', histtype='step', label='train', color='y')\n",
    "plt.hist(np.log10(mse_distr_test_good), bins=bins, density=1, lw=2, histtype='step', label='test good', color='blue')\n",
    "plt.hist(np.log10(mse_distr_test_bad),  bins=bins, density=1, lw=2, histtype='step', label='test bad', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('log (MSE)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MSE by column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_columns_train     = ((x_train - x_pred_train)**2).mean(axis=0)\n",
    "mse_columns_val       = ((x_val - x_pred_val)**2).mean(axis=0)\n",
    "mse_columns_test_good = ((x_test_good - x_pred_test_good)**2).mean(axis=0)\n",
    "mse_columns_test_bad  = ((x_test_bad - x_pred_test_bad)**2).mean(axis=0)\n",
    "mse_columns_all       = ((x_all - x_pred_all)**2).mean(axis=0)\n",
    "\n",
    "for i_c, (c, train, test_g, test_b) in enumerate(zip(input_data.columns, mse_columns_train, mse_columns_test_good, mse_columns_test_bad)):\n",
    "    print(f'{i_c:3.0f}. {c:<30s}: {train:.3f}, \\t {test_g:.3f}, {test_b:6.3f}, \\t {test_b/test_g:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_errors.plot_AE_error(mse_columns_all, input_data.columns, ylabels='AE squared error\\n(all instances)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = ae_errors.plot_AE_error([mse_columns_train, mse_columns_val, mse_columns_test_good, mse_columns_test_bad], \n",
    "                        ylabels=[   'train',           'val',           'test_good',           'test_bad'],\n",
    "                        columns=input_data.columns);\n",
    "# for i in range(3): axes[i].set_ylim([0,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE by interactionRate bins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     28
    ]
   },
   "outputs": [],
   "source": [
    "def plot_histos_irate_bins(bin_to_highlight, irate_nbins, histo_nbins, qlow, qhigh):\n",
    "    colors = ['lime', 'r', 'b', 'c', 'k']\n",
    "    bins = np.linspace(np.quantile(np.log10(mse_distr_all), 0), np.quantile(np.log10(mse_distr_all), 1), histo_nbins)\n",
    "    xmin = np.quantile(np.log10(mse_distr_all), qlow)\n",
    "    xmax = np.quantile(np.log10(mse_distr_all), qhigh)\n",
    "    max_bin_val = 0    \n",
    "    plt.subplots(1,1, figsize=(12,6))\n",
    "    for i,color in zip(range(1,irate_nbins+1), colors):\n",
    "        idx = df.query(f'irate_bin{irate_nbins} == @i').index\n",
    "        counts, xs, _ = plt.hist(np.log10(mse_distr_all[ idx ]),  bins=bins, density=1, lw=2, histtype='step', label=f'bin {i}/{irate_nbins}', color=color)\n",
    "        for c,x in zip(counts, xs[1:]):\n",
    "            if x > xmin:\n",
    "                max_bin_val = max(max_bin_val, c)\n",
    "\n",
    "    if bin_to_highlight in range(1,irate_nbins+1):\n",
    "        idx = df.query(f'irate_bin{irate_nbins} == {bin_to_highlight}').index\n",
    "        plt.hist(np.log10(mse_distr_all[ idx ]),  bins=bins, density=1, lw=6, histtype='step', color=colors[bin_to_highlight-1])\n",
    "\n",
    "    plt.legend();\n",
    "    plt.xlim(xmin, xmax )\n",
    "#     plt.ylim(top = max_bin_val*1.2)\n",
    "    plt.semilogy()\n",
    "    \n",
    "\n",
    "wg_bins_highlight = widgets.Dropdown(description='bin to highlight', options=[0,1,2,3,4,5])\n",
    "wg_nbins = widgets.IntSlider(description='n bins', min=5, max=60, value=20, step=5, continuous_update=False)\n",
    "wg_qlow = widgets.FloatSlider(description='lower quantile', min=0, max=1, value=0.0, step=0.005, continuous_update=False)\n",
    "wg_qhigh = widgets.FloatSlider(description='upper quantile', min=0, max=1, value=1, step=0.005, continuous_update=False)\n",
    "wg_irate_nbins = widgets.RadioButtons(description='interactionRate nbins', options=[3,5], value=5)\n",
    "\n",
    "ui = widgets.HBox([wg_bins_highlight])\n",
    "ui_quantiles = widgets.HBox([wg_qlow, wg_qhigh])\n",
    "ui_nbins = widgets.HBox([wg_nbins, wg_irate_nbins])\n",
    "\n",
    "out = widgets.interactive_output(plot_histos_irate_bins, {'bin_to_highlight': wg_bins_highlight, \n",
    "                                                          'histo_nbins':wg_nbins,\n",
    "                                                          'irate_nbins':wg_irate_nbins,\n",
    "                                                          'qlow':wg_qlow,\n",
    "                                                          'qhigh':wg_qhigh\n",
    "                                                          })\n",
    "display(ui_quantiles)\n",
    "display(ui_nbins)\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in df.index:\n",
    "    if df.iloc[index]['bad'] == 1: continue\n",
    "    mse_instance = (x_all[index,:]-x_pred_all[index,:])**2 \n",
    "    log_mse = np.log10(mse_instance.mean())\n",
    "    arrow = '\\t\\t<------' if log_mse > 0.5 else ''\n",
    "    print(f'{index:5d}: {log_mse:7.4f} {arrow}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_index = 145\n",
    "irate_nbins = 5\n",
    "#----------------------\n",
    "\n",
    "row_orig = df_orig.iloc[instance_index]\n",
    "row      = df.iloc[instance_index]\n",
    "global_warning_flag = row_orig['alias_global_Warning']\n",
    "mse_instance_number = mse_distr_all[instance_index]\n",
    "mse_percentile = percentileofscore(mse_distr_all, mse_instance_number)\n",
    "\n",
    "instance_irate = row['interactionRate']\n",
    "instance_irate_bin = assign_irate_bin5(row) if irate_nbins == 5 else assign_irate_bin3(row)\n",
    "\n",
    "status_str =  f\"chunk {instance_index} [ {row_orig['period.fString']} / {row_orig['run']} / chunk {row_orig['chunkID']} ]:  \\n - _globalWarning_ flag set to: **{bool(global_warning_flag)}**  \\n  MSE = **{mse_instance_number:.3f}**  \\n  log(MSE) = **{np.log10(mse_instance_number):.3f}**  \\n  \\n interactionRate = {instance_irate:.1f} (bin **{instance_irate_bin}**/{irate_nbins})\"\n",
    "printmd(status_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_instance = (x_all[instance_index,:]-x_pred_all[instance_index,:])**2 \n",
    "\n",
    "irate_bin_idx = df.query(f'irate_bin{irate_nbins} == {instance_irate_bin}').index\n",
    "mse_columns_irate_bin = ((x_all[irate_bin_idx] - x_pred_all[irate_bin_idx])**2).mean(axis=0)\n",
    "\n",
    "mse_instance_relative_all       = mse_instance / mse_columns_all\n",
    "mse_instance_relative_irate_bin = mse_instance / mse_columns_irate_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histos\n",
    "nbins = 30\n",
    "fig,axes = plt.subplots(1,2, figsize=(16,4))\n",
    "\n",
    "ax = axes[0]\n",
    "bins = np.linspace(np.quantile(np.log10(mse_distr_all), 0), np.quantile(np.log10(mse_distr_all), 1), nbins)\n",
    "ax.hist(np.log10(mse_distr_train), bins=bins, density=1, lw=2, ls='-.', histtype='step', label='train', color='y')\n",
    "ax.hist(np.log10(mse_distr_test_good), bins=bins, density=1, lw=2, histtype='step', label='test good', color='blue')\n",
    "ax.hist(np.log10(mse_distr_test_bad),  bins=bins, density=1, lw=2, histtype='step', label='test bad', color='red')\n",
    "\n",
    "# ax.hist(np.log10(mse_distr_all[ df.query(f'irate_bin3 == {instance_irate_bin}').index ]),  bins=bins, density=1, lw=2, histtype='step', label=f'bin {instance_irate_bin}/3', color='k')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('log (MSE)');\n",
    "\n",
    "xrange = ax.get_xlim()[1] - ax.get_xlim()[0]\n",
    "yrange = ax.get_ylim()[1] - ax.get_ylim()[0]\n",
    "ax.arrow(np.log10(mse_instance.mean()), yrange*0.95, 0, -0.2*yrange, \n",
    "            width=0.01*xrange, fc='k')\n",
    "ax.text(np.log10(mse_instance.mean())-0.1, yrange*0.85, f'{mse_instance.mean():.2f}\\nlog={np.log10(mse_instance.mean()):.2f}', horizontalalignment='right', fontdict=dict(fontsize=14));\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "ax = axes[1]\n",
    "bins = np.linspace(np.quantile(np.log10(mse_distr_all), 0), np.quantile(np.log10(mse_distr_all), 1), nbins)\n",
    "# ax.hist(np.log10(mse_distr_train), bins=bins, density=1, lw=2, ls='-.', histtype='step', label='train', color='y')\n",
    "# ax.hist(np.log10(mse_distr_test_good), bins=bins, density=1, lw=2, histtype='step', label='test good', color='blue')\n",
    "# ax.hist(np.log10(mse_distr_test_bad),  bins=bins, density=1, lw=2, histtype='step', label='test bad', color='red')\n",
    "\n",
    "ax.hist(np.log10(mse_distr_all),  bins=bins, density=1, lw=2, histtype='step', label=f'all bins', color='gray')\n",
    "ax.hist(np.log10(mse_distr_all[ df.query(f'irate_bin5 == {instance_irate_bin}').index ]),  bins=bins, density=1, lw=2, histtype='step', label=f'bin {instance_irate_bin}/5', color='k')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('log (MSE)');\n",
    "\n",
    "xrange = ax.get_xlim()[1] - ax.get_xlim()[0]\n",
    "yrange = ax.get_ylim()[1] - ax.get_ylim()[0]\n",
    "ax.arrow(np.log10(mse_instance.mean()), yrange*0.95, 0, -0.2*yrange, \n",
    "            width=0.01*xrange, fc='k')\n",
    "ax.text(np.log10(mse_instance.mean())-0.1, yrange*0.85, f'{mse_instance.mean():.2f}\\nlog={np.log10(mse_instance.mean()):.2f}', horizontalalignment='right', fontdict=dict(fontsize=14));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(3,1,figsize=(50,15))\n",
    "ae_errors.plot_AE_error([mse_instance, \n",
    "                         mse_instance_relative_all, \n",
    "                         mse_instance_relative_irate_bin], \n",
    "                        ylabels=\n",
    "                        [f'squared errors\\ninstance={instance_index}', \n",
    "                          'sq. errors relative to\\naver. (column) error',\n",
    "                          'sq. errors relative to\\naver. in this IRate bin'],\n",
    "                        columns=input_data.columns,\n",
    "                       axes=axes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_qa_plots(df_orig.iloc[instance_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "1. Compare with AE trained on both _good_ and _bad_\n",
    "2. Check correlations of MSE of columns\n",
    "3. Find justification for bad chunks of being rejected!  \n",
    "   Then also look at apropriate QA control plots and see what can be wrong\n",
    "4. Train AE without matching eff. and use it as flags  \n",
    "   search for matching eff. to other detectors\n",
    "5. Overall AE reproducibility - impact of architecture/training data on scores for particular chunks\n",
    "6. Permutation importance (after repro check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
