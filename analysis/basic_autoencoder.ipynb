{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_orig = pd.read_csv('data/trending_merged_LHC18q_withGraphs.csv')\n",
    "\n",
    "target_col = 'alias_global_Warning'\n",
    "#----------\n",
    "\n",
    "df = df_orig[[c for c in df_orig.columns if \n",
    "              ('gr' not in c and 'alias' not in c and 'Unnamed' not in c)\n",
    "              and c != 'dataType.fString'\n",
    "              or c == target_col\n",
    "             ]]\n",
    "rename = lambda c: c if c != target_col else 'bad'\n",
    "df.columns = [rename(c) for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()\n",
    "nonphysical_cols = ['run', 'chunkID', 'time', \n",
    "                   'year', 'period.fString', 'pass.fString', 'runType.fString', \n",
    "                   'startTimeGRP', 'stopTimeGRP', 'duration', \n",
    "                   'iroc_A_side', 'oroc_A_side', 'iroc_C_side', 'oroc_C_side',\n",
    "                   'chunkStart', 'chunkStop', 'chunkMean', 'chunkMedian', 'chunkRMS', 'chunkDuration']\n",
    "\n",
    "no_variance_cols = df.std()[(df.std() < 1e-6).tolist()].index.tolist()\n",
    "cols_exclude_corr = nonphysical_cols + no_variance_cols\n",
    "\n",
    "for c in df.columns:\n",
    "    if c not in cols_exclude_corr:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "THRESHOLD = 1.01\n",
    "\n",
    "corr = df[[c for c in df.columns if c not in cols_exclude_corr]].corr()\n",
    "s = corr.abs().unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.hist(so, histtype='step', bins=100);\n",
    "plt.title('histo of corr. coef.');\n",
    "ylim = plt.ylim()\n",
    "y_l = ylim[0] + ylim[1]*0.15\n",
    "y_h = ylim[0] + ylim[1]*0.4\n",
    "arrow = mpatches.FancyArrowPatch((THRESHOLD, y_h), (THRESHOLD, y_l),\n",
    "                                 mutation_scale=25, color='red', \n",
    "                                 arrowstyle='fancy');\n",
    "ax.add_patch(arrow);\n",
    "ax.text(THRESHOLD-0.03, y_h, f'{THRESHOLD}');\n",
    "\n",
    "cols_no_corr = corr.columns.tolist()\n",
    "for c1 in corr.columns:\n",
    "    for c2 in corr.columns:\n",
    "        if corr.columns.tolist().index(c1) <= corr.columns.tolist().index(c2): continue\n",
    "        cval = corr.abs()[c1][c2]\n",
    "        if cval > THRESHOLD and  c1 in cols_no_corr and c2 in cols_no_corr:\n",
    "            cols_no_corr.remove(c2)\n",
    "#             print(f'{c2} removed due to its corr. with {c1} = {cval:.3f}')\n",
    "print('\\n\\n', cols_no_corr)\n",
    "print(f'\\n{len(cols_no_corr)} out of {len(corr.columns)} columns were selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols_no_corr].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df[cols_no_corr].query('bad == 0')\n",
    "input_data = input_data.drop(['bad'], axis=1)\n",
    "x = input_data.to_numpy()\n",
    "x_s = StandardScaler().fit(x).transform(x)\n",
    "\n",
    "x_train, x_val = train_test_split(x_s, test_size=0.1)  # x_val are GOOD samples used to monitor overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df[cols_no_corr].drop('bad', axis=1)\n",
    "x = input_data.to_numpy()\n",
    "x_s = StandardScaler().fit(x).transform(x)\n",
    "# x_s = pd.DataFrame(x_s, columns=df.columns)\n",
    "# x_s['bad'] = df['bad']\n",
    "y = df['bad'].to_numpy()\n",
    "\n",
    "x_test_bad = x_s[y == 1]\n",
    "\n",
    "x_train_val_good, x_test_good = train_test_split(x_s[y == 0], test_size=0.1)  \n",
    "x_train, x_val = train_test_split(x_train_val_good, test_size=0.1)  # x_val are GOOD samples used to monitor overfitting\n",
    "\n",
    "# y_test_good = np.zeros(x_test_good.shape[0])\n",
    "# y_test_bad  = np.ones(x_test_bad.shape[0])\n",
    "\n",
    "# x_test = np.concatenate([x_test_good, x_test_bad])\n",
    "# y_test = np.concatenate([y_test_good, y_test_bad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our input placeholder\n",
    "input_size = x_train.shape[1]\n",
    "coding_layers_sizes = [32,16]\n",
    "bottleneck_size = 8\n",
    "\n",
    "ae_input = Input(shape=(input_size,))\n",
    "encoded = Dense(coding_layers_sizes[0], activation='relu')(ae_input)\n",
    "for lsize in coding_layers_sizes[1:]:\n",
    "    encoded = Dense(lsize, activation='relu')(encoded)\n",
    "#     encoded = Dropout(0.2)(encoded)\n",
    "encoded = Dense(bottleneck_size, activation='relu')(encoded)\n",
    "    \n",
    "# encoded = Dense(8, activation='relu')(encoded)\n",
    "# encoded = Dense(4, activation='relu')(encoded)\n",
    "# encoded = Dense(8, activation='relu')(encoded)\n",
    "\n",
    "# decoded = Dense(input_size, activation='linear')(encoded)\n",
    "\n",
    "decoded = Dense(coding_layers_sizes[-1], activation='relu')(encoded)\n",
    "for lsize in reversed(coding_layers_sizes[:-1]):\n",
    "    decoded = Dense(lsize, activation='relu')(decoded)\n",
    "# decoded = Dense(32, activation='relu')(decoded)\n",
    "# decoded = Dense(16, activation='relu')(decoded)\n",
    "decoded = Dense(input_size, activation='linear')(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(ae_input, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(ae_input, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "fit = autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=32,\n",
    "                verbose=2,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = fit.history['loss']\n",
    "val_loss = fit.history['val_loss']\n",
    "epochs = fit.epoch\n",
    "\n",
    "plt.plot(epochs, loss, 'bx--', label='train loss', color='blue')\n",
    "plt.plot(epochs, val_loss, 'rx--', label='val loss', color='green')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "x_pred_train     = autoencoder.predict(x_train)\n",
    "x_pred_val       = autoencoder.predict(x_val)\n",
    "x_pred_test_good = autoencoder.predict(x_test_good)\n",
    "x_pred_test_bad  = autoencoder.predict(x_test_bad)\n",
    "\n",
    "mse_train     = mean_squared_error(x_train, x_pred_train)\n",
    "mse_val       = mean_squared_error(x_val, x_pred_val)\n",
    "mse_test_good = mean_squared_error(x_test_good, x_pred_test_good)\n",
    "mse_test_bad  = mean_squared_error(x_test_bad, x_pred_test_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE:\\n\\t train = {mse_train:.3f}\\n\\t val = {mse_val:.3f}\\n\\t test_good = {mse_test_good:.3f}\\n\\t test_bad = {mse_test_bad:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_distr_train = ((x_train - x_pred_train)**2).mean(axis=1)\n",
    "mse_distr_val = ((x_val - x_pred_val)**2).mean(axis=1)\n",
    "mse_distr_test_good = ((x_test_good - x_pred_test_good)**2).mean(axis=1)\n",
    "mse_distr_test_bad = ((x_test_bad - x_pred_test_bad)**2).mean(axis=1)\n",
    "\n",
    "mse_distr = np.concatenate([mse_distr_train, mse_distr_val, mse_distr_test_good, mse_distr_test_bad])\n",
    "\n",
    "# for mse_d in [mse_distr_train, mse_distr_val, mse_distr_test_good, mse_distr_test_bad]:\n",
    "#     mse_d = np.log10(mse_d)\n",
    "\n",
    "# bins = np.linspace(np.quantile(mse_distr, 0), np.quantile(mse_distr, 0.999), 100)\n",
    "\n",
    "# plt.hist(mse_distr_train, bins=bins, density=1, lw=2, histtype='step', label='train', color='blue')\n",
    "# plt.hist(mse_distr_val, bins=bins, density=1, lw=2, histtype='step', label='val', color='green')\n",
    "# plt.hist(mse_distr_test_good, bins=bins, density=1, lw=2, histtype='step', label='test good', color='red')\n",
    "# plt.hist(mse_distr_test_bad, bins=bins, density=1, lw=2, histtype='step', label='test bad', color='k')\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "bins = np.linspace(np.quantile(np.log10(mse_distr), 0), np.quantile(np.log10(mse_distr), 1), 30)\n",
    "\n",
    "# plt.hist(np.log10(mse_distr_test_good), bins=bins, density=1, lw=2, alpha=0.1, color='red')\n",
    "# plt.hist(np.log10(mse_distr_test_bad), bins=bins, density=1, lw=2,  alpha=0.1, color='k')\n",
    "\n",
    "\n",
    "# plt.hist(np.log10(mse_distr_train),     bins=bins, density=1, lw=2, histtype='step', label='train', color='blue')\n",
    "# plt.hist(np.log10(mse_distr_val),       bins=bins, density=1, lw=2, histtype='step', label='val', color='c')\n",
    "plt.hist(np.log10(mse_distr_test_good), bins=bins, density=1, lw=2, histtype='step', label='test good', color='red')\n",
    "plt.hist(np.log10(mse_distr_test_bad),  bins=bins, density=1, lw=2, histtype='step', label='test bad', color='k')\n",
    "plt.legend()\n",
    "plt.xlabel('log (MSE)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'TPCnCl'\n",
    "print(s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_indices = dict()\n",
    "\n",
    "\n",
    "for group_name, group_func in [\n",
    "                                ('TPC-ncl', lambda col: 'TPC' in col), \n",
    "                                ('vertex', lambda col: 'vert' in col.lower()),\n",
    "                                ('dZ-fits', lambda col: 'dZA' in col or 'dZC' in col),\n",
    "                                ('dR-fits', lambda col: 'dRA' in col or 'dRC' in col),\n",
    "                                ('multiplicity', lambda col: 'Mult' in col),\n",
    "                                ('pT', lambda col: ('PtA' in col or 'PtC' in col or 'qOverPt' in col) and 'tpcIts' not in col and 'deltaPt' not in col),\n",
    "                                ('delta pT', lambda col: 'deltaPt' in col),\n",
    "                                ('DCA', lambda col: ('dcar' in col or 'dcaz' in col) and 'dcarAP' not in col and 'dcarCP' not in col),\n",
    "                                ('MIP', lambda col: ('MIP' in col)),\n",
    "                                ('TPC-ITS_match.', lambda col: 'tpcIts' in col),\n",
    "                                ('distr._pulls', lambda col: 'Pull' in col),\n",
    "                                ('work_conditions', lambda col: 'PTR' in col or 'HVandPT' in col or 'VDrift' in col),\n",
    "                                ]:\n",
    "    lst = []\n",
    "    print()\n",
    "    print(group_name, ':\\n------', )\n",
    "    \n",
    "    for i_c, c in enumerate(input_data.columns):\n",
    "        if group_func(c):\n",
    "            lst.append(i_c)\n",
    "#             print(c)\n",
    "        \n",
    "    lst = np.array(lst)\n",
    "    print(all(lst[1:] - lst[:-1] == 1))\n",
    "    print(lst[1:] - lst[:-1] == 1)\n",
    "    print(lst)\n",
    "    groups_indices[group_name] = lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_columns_train = ((x_train - x_pred_train)**2).mean(axis=0)\n",
    "mse_columns_val = ((x_val - x_pred_val)**2).mean(axis=0)\n",
    "mse_columns_test_good = ((x_test_good - x_pred_test_good)**2).mean(axis=0)\n",
    "mse_columns_test_bad = ((x_test_bad - x_pred_test_bad)**2).mean(axis=0)\n",
    "\n",
    "for i_c, (c, train, test_g, test_b) in enumerate(zip(input_data.columns, mse_columns_train, mse_columns_test_good, mse_columns_test_bad)):\n",
    "    print(f'{i_c:3.0f}. {c:<30s}: {train:.3f}, \\t {test_g:.3f}, {test_b:6.3f}, \\t {test_b/test_g:.2f}')\n",
    "\n",
    "# idx = np.argsort(mse_columns_train)\n",
    "# for i in idx:\n",
    "#     print(input_data.columns[i], mse_columns_train[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "style = \"\"\"\n",
    "<style>\n",
    "div.output_area {\n",
    "    overflow-y: scroll;\n",
    "}\n",
    "div.output_area img {\n",
    "    max-width: unset;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "HTML(style) \n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(4,1, figsize=(50,20))\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "for i,mse_columns in enumerate([mse_columns_train, mse_columns_val, mse_columns_test_good, mse_columns_test_bad]):\n",
    "    ax = axes[i]\n",
    "    ax.bar(range(mse_columns_train.shape[0]), mse_columns, width=0.5)\n",
    "    ax.set_xlim([-5, len(input_data.columns)+5])\n",
    "    ax.set_xticks(range(0, len(input_data.columns)))\n",
    "    ax.set_xticklabels(labels=input_data.columns, rotation=90, horizontalalignment='center')\n",
    "#     ax.semilogy()\n",
    "    \n",
    "    ymax = ax.get_ylim()[1]\n",
    "\n",
    "    for group_name, indices in groups_indices.items():\n",
    "        ax.vlines([np.min(indices)-0.5, np.max(indices)+0.5], 0, ymax, linestyles='--')\n",
    "        ax.text(np.mean(indices), 0.8*ymax, group_name.replace('_', '\\n'), horizontalalignment='center', fontdict=dict(fontsize=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_good.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance_index in range(91):\n",
    "    mse_instance = (x_test_bad[instance_index,:]-x_pred_test_bad[instance_index,:])**2 \n",
    "    log_mse = np.log10(mse_instance.mean())\n",
    "    arrow = '\\t\\t<------' if log_mse > 1 else ''\n",
    "    print(f'{instance_index}: {log_mse} {arrow}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_index = 90\n",
    "mse_instance = (x_test_bad[instance_index,:]-x_pred_test_bad[instance_index,:])**2 \n",
    "\n",
    "\n",
    "bins = np.linspace(np.quantile(np.log10(mse_distr), 0), np.quantile(np.log10(mse_distr), 1), 30)\n",
    "\n",
    "# plt.hist(np.log10(mse_distr_test_good), bins=bins, density=1, lw=2, alpha=0.1, color='red')\n",
    "# plt.hist(np.log10(mse_distr_test_bad), bins=bins, density=1, lw=2,  alpha=0.1, color='k')\n",
    "# plt.hist(np.log10(mse_distr_train),     bins=bins, density=1, lw=2, histtype='step', label='train', color='blue')\n",
    "# plt.hist(np.log10(mse_distr_val),       bins=bins, density=1, lw=2, histtype='step', label='val', color='c')\n",
    "plt.hist(np.log10(mse_distr_test_good), bins=bins, density=1, lw=2, histtype='step', label='test good', color='red')\n",
    "plt.hist(np.log10(mse_distr_test_bad),  bins=bins, density=1, lw=2, histtype='step', label='test bad', color='k')\n",
    "plt.legend()\n",
    "plt.xlabel('log (MSE)');\n",
    "\n",
    "xrange = plt.xlim()[1] - plt.xlim()[0]\n",
    "yrange = plt.ylim()[1] - plt.ylim()[0]\n",
    "plt.arrow(np.log10(mse_instance.mean()), yrange*0.95, 0, -0.2*yrange, \n",
    "            width=0.01*xrange, \n",
    "#             length_includes_head=True, head_length=0.1*yrange, head_width=0.02*xrange,\n",
    "                fc='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "style = \"\"\"\n",
    "<style>\n",
    "div.output_area {\n",
    "    overflow-y: scroll;\n",
    "}\n",
    "div.output_area img {\n",
    "    max-width: unset;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "HTML(style) \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(50,8))\n",
    "ax.bar(range(mse_columns_train.shape[0]), mse_instance, width=0.5)\n",
    "# ax.set_xlim([0, len(input_data.columns)])\n",
    "# tick_locs = ax.get_xticks()\n",
    "ax.set_xlim([-5, len(input_data.columns)+5])\n",
    "ax.set_xticks(range(0, len(input_data.columns)))\n",
    "ax.set_xticklabels(labels=input_data.columns, rotation=90, horizontalalignment='center')\n",
    "\n",
    "ymax = ax.get_ylim()[1]\n",
    "\n",
    "for group_name, indices in groups_indices.items():\n",
    "    ax.vlines([np.min(indices)-0.5, np.max(indices)+0.5], 0, ymax, linestyles='--')\n",
    "    ax.text(np.mean(indices), 0.8*ymax, group_name.replace('_', '\\n'), horizontalalignment='center', fontdict=dict(fontsize=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_good_r = x_test_good.reshape([np.product(x_test_good.shape),1])\n",
    "x_pred_test_good_r = x_pred_test_good.reshape([np.product(x_pred_test_good.shape),1])\n",
    "mean_squared_error(x_test_good_r, x_pred_test_good_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "1. train **basic** AE (feature scaling, training only on good time intervals? ) - DONE\n",
    "2. try to viz. it - ?\n",
    "3. check dependence: \n",
    "    - on overall performance w/ and w/o _bad_ timeIntervals, \n",
    "    - performance on _bad_ and _good_ timeIntervals - DONE\n",
    "__________________\n",
    "4. Compare with AE trained on both _good_ and _bad_\n",
    "5. Check correlations of MSE of columns\n",
    "6. Try to viz. columns sq. errors as a ratio to aver. sq. error of this column (of train / test_all / test_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
