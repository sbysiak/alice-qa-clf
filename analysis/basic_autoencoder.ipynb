{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import adadelta\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "from helper import ae_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "style = \"\"\"\n",
    "<style>\n",
    "div.output_area {\n",
    "    overflow-y: scroll;\n",
    "}\n",
    "div.output_area img {\n",
    "    max-width: unset;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "def make_cell_scrollable():\n",
    "    HTML(style)\n",
    "    \n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Input preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "df_orig = pd.read_csv('data/trending_merged_LHC18q_withGraphs.csv')\n",
    "\n",
    "target_col = 'alias_global_Warning'\n",
    "#----------\n",
    "\n",
    "df = df_orig[[c for c in df_orig.columns if \n",
    "              ('gr' not in c and 'alias' not in c and 'Unnamed' not in c)\n",
    "              and c != 'dataType.fString'\n",
    "              or c == target_col\n",
    "             ]]\n",
    "rename = lambda c: c if c != target_col else 'bad'\n",
    "df.columns = [rename(c) for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.columns.tolist()\n",
    "nonphysical_cols = ['run', 'chunkID', 'time', \n",
    "                   'year', 'period.fString', 'pass.fString', 'runType.fString', \n",
    "                   'startTimeGRP', 'stopTimeGRP', 'duration', \n",
    "                   'iroc_A_side', 'oroc_A_side', 'iroc_C_side', 'oroc_C_side',\n",
    "                   'chunkStart', 'chunkStop', 'chunkMean', 'chunkMedian', 'chunkRMS', 'chunkDuration']\n",
    "\n",
    "no_variance_cols = df.std()[(df.std() < 1e-6).tolist()].index.tolist()\n",
    "cols_exclude = nonphysical_cols + no_variance_cols\n",
    "\n",
    "for c in df.columns:\n",
    "    if c not in cols_exclude:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_data = df[[c for c in df.columns if c not in cols_exclude]].drop('bad', axis=1)\n",
    "\n",
    "for i in range(5):\n",
    "    input_data[f'random{i}'] = np.random.randn(len(input_data))\n",
    "\n",
    "x = input_data.to_numpy()\n",
    "y = df['bad'].to_numpy()\n",
    "\n",
    "x_test_bad = x[y == 1]\n",
    "x_train_val_good, x_test_good = train_test_split(x[y == 0], test_size=0.1)  \n",
    "x_train, x_val = train_test_split(x_train_val_good, test_size=0.1)  # x_val are GOOD samples used to monitor overfitting\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# scaler = MaxAbsScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train     = scaler.transform(x_train)\n",
    "x_val       = scaler.transform(x_val)\n",
    "x_test_good = scaler.transform(x_test_good)\n",
    "x_test_bad  = scaler.transform(x_test_bad)\n",
    "x_all       = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## InteractionRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "jitter_y = 1500\n",
    "#-------------\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.plot(df['chunkMean'], df['interactionRate']+np.random.random(len(df))*jitter_y, '.', ms=3)\n",
    "# plt.plot(df.query('bad == 0')['chunkMean'], df.query('bad == 0')['interactionRate']+np.random.random(len(df.query('bad == 0')))*jitter_y, '.', ms=2, color='b')\n",
    "# plt.plot(df.query('bad == 1')['chunkMean'], df.query('bad == 1')['interactionRate']+np.random.random(len(df.query('bad == 1')))*jitter_y, '.', ms=8, marker='x', color='r')\n",
    "plt.xlabel('chunk mean time');\n",
    "plt.ylabel('interactionRate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plt.hist(df.query('bad == 0')['interactionRate'], bins=20, histtype='step', color='b', density=1)\n",
    "# plt.hist(df.query('bad == 1')['interactionRate'], bins=20, histtype='step', color='r', density=1)\n",
    "\n",
    "plt.hist(df['interactionRate'], bins=50, histtype='step', color='b', density=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# this is our input placeholder\n",
    "input_size = x_train.shape[1]\n",
    "coding_layers_sizes = [64,32]\n",
    "bottleneck_size = 16\n",
    "\n",
    "ae_input = Input(shape=(input_size,))\n",
    "encoded = Dense(coding_layers_sizes[0], activation='relu')(ae_input)\n",
    "for lsize in coding_layers_sizes[1:]:\n",
    "    encoded = Dense(lsize, activation='relu')(encoded)\n",
    "#     encoded = Dropout(0.2)(encoded)\n",
    "encoded = Dense(bottleneck_size, activation='relu')(encoded)\n",
    "    \n",
    "# encoded = Dense(8, activation='relu')(encoded)\n",
    "# encoded = Dense(4, activation='relu')(encoded)\n",
    "# encoded = Dense(8, activation='relu')(encoded)\n",
    "\n",
    "# decoded = Dense(input_size, activation='linear')(encoded)\n",
    "\n",
    "decoded = Dense(coding_layers_sizes[-1], activation='relu')(encoded)\n",
    "for lsize in reversed(coding_layers_sizes[:-1]):\n",
    "    decoded = Dense(lsize, activation='relu')(decoded)\n",
    "# decoded = Dense(32, activation='relu')(decoded)\n",
    "# decoded = Dense(16, activation='relu')(decoded)\n",
    "decoded = Dense(input_size, activation='linear')(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(ae_input, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(ae_input, decoded)\n",
    "autoencoder.compile(optimizer=adadelta(lr=0.2), loss='mean_squared_error')\n",
    "\n",
    "fit = autoencoder.fit(x_train, x_train, \n",
    "                epochs=20,\n",
    "                batch_size=32,\n",
    "                verbose=2,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, x_val),\n",
    "                callbacks=[PlotLossesKeras()])\n",
    "PlotLossesKeras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss = fit.history['loss']\n",
    "val_loss = fit.history['val_loss']\n",
    "epochs = fit.epoch\n",
    "\n",
    "plt.plot(epochs, loss, 'bx--', label='train loss', color='blue')\n",
    "plt.plot(epochs, val_loss, 'rx--', label='val loss', color='green')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fit.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Compute predictions and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "x_pred_train     = autoencoder.predict(x_train)\n",
    "x_pred_val       = autoencoder.predict(x_val)\n",
    "x_pred_test_good = autoencoder.predict(x_test_good)\n",
    "x_pred_test_bad  = autoencoder.predict(x_test_bad)\n",
    "x_pred_all       = autoencoder.predict(x_all)\n",
    "\n",
    "mse_train     = mean_squared_error(x_train, x_pred_train)\n",
    "mse_val       = mean_squared_error(x_val, x_pred_val)\n",
    "mse_test_good = mean_squared_error(x_test_good, x_pred_test_good)\n",
    "mse_test_bad  = mean_squared_error(x_test_bad, x_pred_test_bad)\n",
    "mse_all       = mean_squared_error(x_all, x_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'MSE:\\n\\t all = {mse_all:.3f}\\n\\t {\"-\"*10}\\n\\t train = {mse_train:.3f}\\n\\t val = {mse_val:.3f}\\n\\t test_good = {mse_test_good:.3f}\\n\\t test_bad = {mse_test_bad:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mse_distr_train     = ((x_train - x_pred_train)**2).mean(axis=1)\n",
    "mse_distr_val       = ((x_val - x_pred_val)**2).mean(axis=1)\n",
    "mse_distr_test_good = ((x_test_good - x_pred_test_good)**2).mean(axis=1)\n",
    "mse_distr_test_bad  = ((x_test_bad - x_pred_test_bad)**2).mean(axis=1)\n",
    "mse_distr           = ((x_all - x_pred_all)**2).mean(axis=1)\n",
    "\n",
    "# plot histos\n",
    "bins = np.linspace(np.quantile(np.log10(mse_distr), 0), np.quantile(np.log10(mse_distr), 1), 20)\n",
    "plt.hist(np.log10(mse_distr_train), bins=bins, density=1, lw=2, ls='-.', histtype='step', label='train', color='y')\n",
    "plt.hist(np.log10(mse_distr_test_good), bins=bins, density=1, lw=2, histtype='step', label='test good', color='blue')\n",
    "plt.hist(np.log10(mse_distr_test_bad),  bins=bins, density=1, lw=2, histtype='step', label='test bad', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('log (MSE)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**MSE by column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mse_columns_train = ((x_train - x_pred_train)**2).mean(axis=0)\n",
    "mse_columns_val = ((x_val - x_pred_val)**2).mean(axis=0)\n",
    "mse_columns_test_good = ((x_test_good - x_pred_test_good)**2).mean(axis=0)\n",
    "mse_columns_test_bad = ((x_test_bad - x_pred_test_bad)**2).mean(axis=0)\n",
    "mse_columns_all = ((x_all - x_pred_all)**2).mean(axis=0)\n",
    "\n",
    "for i_c, (c, train, test_g, test_b) in enumerate(zip(input_data.columns, mse_columns_train, mse_columns_test_good, mse_columns_test_bad)):\n",
    "    print(f'{i_c:3.0f}. {c:<30s}: {train:.3f}, \\t {test_g:.3f}, {test_b:6.3f}, \\t {test_b/test_g:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ae_errors.plot_AE_error(mse_columns_all, input_data.columns);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "isinstance(list(mse_columns_all), list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ae_errors.plot_AE_error([mse_columns_train, mse_columns_val, mse_columns_test_good, mse_columns_test_bad], \n",
    "                        ylabels=[   'train',           'val',           'test_good',           'test_bad'],\n",
    "                        columns=input_data.columns);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Single instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for index in df.index:\n",
    "    if df.iloc[index]['bad'] == 1: continue\n",
    "    mse_instance = (x_all[index,:]-x_pred_all[index,:])**2 \n",
    "    log_mse = np.log10(mse_instance.mean())\n",
    "    arrow = '\\t\\t<------' if log_mse > 0.5 else ''\n",
    "    print(f'{index:5d}: {log_mse:7.4f} {arrow}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "instance_index = 145\n",
    "\n",
    "row_orig = df_orig.iloc[instance_index]\n",
    "row = x_all[instance_index,:]\n",
    "global_warning_flag = df_orig['alias_global_Warning'].iloc[instance_index]\n",
    "mse_instance_number = mse_distr[instance_index]\n",
    "mse_percentile = percentileofscore(mse_distr, mse_instance_number)\n",
    "\n",
    "status_str =  f\"chunk {instance_index} [ {row_orig['period.fString']} / {row_orig['run']} / chunk {row_orig['chunkID']} ]:  \\n - _globalWarning_ flag set to: **{bool(global_warning_flag)}**  \\n  MSE = **{mse_instance_number:.3f}**  \\n  log(MSE) = **{np.log10(mse_instance_number):.3f}**\"\n",
    "printmd(status_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mse_instance = (x_all[instance_index,:]-x_pred_all[instance_index,:])**2 \n",
    "\n",
    "bins = np.linspace(np.quantile(np.log10(mse_distr), 0), np.quantile(np.log10(mse_distr), 1), 20)\n",
    "\n",
    "# plt.hist(np.log10(mse_distr_test_good), bins=bins, density=1, lw=2, alpha=0.1, color='red')\n",
    "# plt.hist(np.log10(mse_distr_test_bad), bins=bins, density=1, lw=2,  alpha=0.1, color='k')\n",
    "# plt.hist(np.log10(mse_distr_train),     bins=bins, density=1, lw=2, histtype='step', label='train', color='blue')\n",
    "# plt.hist(np.log10(mse_distr_val),       bins=bins, density=1, lw=2, histtype='step', label='val', color='c')\n",
    "plt.hist(np.log10(mse_distr_test_good), bins=bins, density=1, lw=2, histtype='step', label='test good', color='blue')\n",
    "plt.hist(np.log10(mse_distr_test_bad),  bins=bins, density=1, lw=2, histtype='step', label='test bad', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('log (MSE)');\n",
    "\n",
    "xrange = plt.xlim()[1] - plt.xlim()[0]\n",
    "yrange = plt.ylim()[1] - plt.ylim()[0]\n",
    "plt.arrow(np.log10(mse_instance.mean()), yrange*0.95, 0, -0.2*yrange, \n",
    "            width=0.01*xrange, \n",
    "#             length_includes_head=True, head_length=0.1*yrange, head_width=0.02*xrange,\n",
    "                fc='k')\n",
    "plt.text(np.log10(mse_instance.mean())-0.1, yrange*0.9, f'{mse_instance.mean():.2f}', horizontalalignment='right', fontdict=dict(fontsize=14));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mse_instance_relative = mse_instance / mse_columns_all\n",
    "\n",
    "ae_errors.plot_AE_error([mse_instance, mse_instance_relative], \n",
    "                        ylabels=[f'squared errors\\ninstance={instance_index}', 'squared errors relative\\nto aver. (column) error'],\n",
    "                        columns=input_data.columns);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "available_plots = [('Event Information', 'TPC_event_info.png'), ('Cluster Occupancy', 'cluster_occupancy.png'), ('#eta, #phi and pt', 'eta_phi_pt.png'), ('Number of clusters in #eta and #phi', 'cluster_in_detail.png'), ('DCAs vs #eta', 'dca_in_detail.png'), ('TPC dEdx', 'TPC_dEdx_track_info.png'), ('DCAs vs #phi', 'dca_and_phi.png'), ('TPC-ITS matching', 'TPC-ITS.png'), ('dcar vs pT', 'dcar_pT.png'), ('Tracking parameter phi', 'pullPhiConstrain.png'), ('Raw QA Information', 'rawQAInformation.png'), ('Canvas ROC Status OCDB', 'canvasROCStatusOCDB.png'), ('Resolution vs pT and 1/pT', 'res_pT_1overpT.png'), ('Efficiency all charged + findable', 'eff_all+all_findable.png'), ('Efficiency #pi, K, p', 'eff_Pi_K_P.png'), ('Efficiency findable #pi, K, p', 'eff_Pi_K_P_findable.png')]\n",
    "file_names_mapping = dict(available_plots)\n",
    "\n",
    "row_orig = df_orig.iloc[instance_index]\n",
    "path = '/'.join([str(el) for el in row_orig[['year', 'period.fString', 'pass.fString', 'run']].to_list()])\n",
    "path = path.replace('pass1/', 'pass1/000')\n",
    "\n",
    "def show_qa_plot(plot_name, path=path, file_names_mapping=file_names_mapping):\n",
    "    plot_file_name = file_names_mapping[plot_name]\n",
    "    src = f\"http://aliqatpceos.web.cern.ch/aliqatpceos/data/{path}/{plot_file_name}\"\n",
    "    html = f'<img src={src} width=\"1200\" height=\"1200\">'\n",
    "    print(src)\n",
    "    return md(html)\n",
    "    \n",
    "\n",
    "interact(show_qa_plot, plot_name=file_names_mapping.keys(), \n",
    "         path=fixed(path), file_names_mapping=fixed(file_names_mapping));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def permutation_importances_custom(score_func, X):\n",
    "    baseline = score_func(X)\n",
    "    imp = []\n",
    "    imp_abs = []\n",
    "    for col in X.columns:\n",
    "        save = X[col].copy()\n",
    "        X[col] = np.random.permutation(X[col])\n",
    "        m = score_func(X)\n",
    "        X[col] = save\n",
    "#         imp.append( np.mean(baseline - m) )\n",
    "#         imp_abs.append( np.mean(abs(baseline - m)) )\n",
    "        imp.append(m - baseline)\n",
    "#     return np.array(imp), np.array(imp_abs), X.columns.to_numpy()\n",
    "    return np.array(imp), X.columns.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "def score(X):\n",
    "    X_pred = autoencoder.predict(X)\n",
    "    return mean_squared_error(X, X_pred)\n",
    "    \n",
    "\n",
    "X = pd.DataFrame(x_all, columns=input_data.columns)\n",
    "\n",
    "fimps_multirun = []\n",
    "for i in range(3):\n",
    "    fimps, fnames = permutation_importances_custom(score, X)\n",
    "    fimps_multirun.append(fimps)\n",
    "fimps_multirun = np.array(fimps_multirun)\n",
    "fimps_means = fimps_multirun.mean(axis=0)\n",
    "fimps_stds  = fimps_multirun.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = np.argsort(fimps_means)[::-1]\n",
    "for name, imp_mean, imp_std in zip(fnames[idx], fimps_means[idx], fimps_stds[idx]): \n",
    "    print(f'{name:>25s}:  {imp_mean*100:>10.5f} +/- {imp_std*100:>6.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(fimps_means, 30, histtype='step', lw=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ae_errors.plot_AE_error(fimps_means, \n",
    "                        ylabels='feat. importances',\n",
    "                        columns=input_data.columns);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "1. train **basic** AE (feature scaling, training only on good time intervals? ) - DONE\n",
    "2. try to viz. it - ?\n",
    "3. check dependence: \n",
    "    - on overall performance w/ and w/o _bad_ timeIntervals, \n",
    "    - performance on _bad_ and _good_ timeIntervals - DONE\n",
    "__________________\n",
    "4. Compare with AE trained on both _good_ and _bad_\n",
    "5. Check correlations of MSE of columns\n",
    "6. Try to viz. columns sq. errors as a ratio to aver. sq. error of this column (of train / test_all / test_bad) - DONE\n",
    "    - double barplot - upper just sq. errors, lower - divided by column aver.\n",
    "\n",
    "* SHARE GROUPING FUNC. WITH WARSAW\n",
    "\n",
    "____________________\n",
    "As a func. of IRate:  \n",
    "IRate binning: 0-2-4-6-7-8k OR  0-4-7-8k\n",
    "1. Compare AE's scores to: 1) whole distr. (of course) 2) distr. of similar (in terms of IRate) chunks\n",
    "2. Add third barplot - divided by column aver amoung similar chunks\n",
    "\n",
    "____________________\n",
    "Find justification for bad chunks of being rejected!  \n",
    "Then also look at apropriate QA control plots and see what can be wrong\n",
    "____________________\n",
    "Train AE without matching eff. and use it as flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
