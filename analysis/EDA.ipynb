{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_orig = pd.read_csv('data/trending_merged_LHC18q_withGraphs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'alias_global_Warning'\n",
    "#----------\n",
    "\n",
    "df = df_orig[[c for c in df_orig.columns if \n",
    "              ('gr' not in c and 'alias' not in c and 'Unnamed' not in c)\n",
    "              and c != 'dataType.fString'\n",
    "              or c == target_col\n",
    "             ]]\n",
    "rename = lambda c: c if c != target_col else 'bad'\n",
    "df.columns = [rename(c) for c in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate analysis\n",
    "\n",
    "assumes existance of target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 50)\n",
    "df.describe(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('bad==1').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('bad==0').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist1D(var, n_bins, q_low, q_high):\n",
    "    quantiles = [q_low, q_high]\n",
    "    var_good = df.query('bad==0')[var].tolist()\n",
    "    var_bad  = df.query('bad==1')[var].tolist()\n",
    "\n",
    "    plt.figure()\n",
    "    fig, axes = plt.subplots(1,3, figsize=(18,5))\n",
    "    for i in range(3):\n",
    "        qs = [0,1] if not i else quantiles\n",
    "        quantile_vals = np.quantile(var_good+var_bad, qs)\n",
    "        _, bins = np.histogram(var_good + var_bad, bins=n_bins, range=quantile_vals)\n",
    "        normed = (i == 2)\n",
    "        axes[i].hist(var_good, bins=bins, alpha=1, color='blue', linewidth=1.2, histtype='step', linestyle='-', density=normed)\n",
    "        axes[i].hist(var_bad, bins=bins, alpha=1, edgecolor='red', linewidth=2, histtype='step', density=normed)\n",
    "\n",
    "\n",
    "        for qv in quantile_vals: \n",
    "            axes[0].axvline(qv, linestyle='--', color='grey')\n",
    "#             axes[0].text()\n",
    "        axes[0].set_title('whole range')\n",
    "        axes[1].set_title(f'limited range (q={quantiles[0]*100:.0f},{quantiles[1]*100:.0f}): {quantile_vals[0]:.3f}, {quantile_vals[1]:.3f}')\n",
    "        axes[2].set_title('normalized per class')\n",
    "\n",
    "        plt.suptitle(var)\n",
    "\n",
    "#w_nbins = interactive(lambda n: n, n=(3,100,1));\n",
    "#display(w_nbins)\n",
    "#print(w_nbins.kwargs)\n",
    "#w_varname.observe(update_x_range, 'value')\n",
    "\n",
    "# plt.text?\n",
    "\n",
    "wg_colname = widgets.Dropdown(description='column name', options=df.columns)\n",
    "wg_nbins = widgets.IntSlider(description='n bins', min=3, max=100, value=20, step=1, continuous_update=False)\n",
    "wg_qlow = widgets.FloatSlider(description='lower quantile', min=0, max=0.3, value=0.01, step=0.01, continuous_update=False)\n",
    "wg_qhigh = widgets.FloatSlider(description='upper quantile', min=0.7, max=1, value=0.99, step=0.01, continuous_update=False)\n",
    "\n",
    "def make_plot(name, n_bins):\n",
    "    print('making plot of {} with {} bins'.format(name, n_bins))\n",
    "ui = widgets.HBox([wg_colname, wg_nbins])\n",
    "ui2 = widgets.HBox([wg_qlow, wg_qhigh])\n",
    "\n",
    "out = widgets.interactive_output(plot_hist1D, {'var': wg_colname, 'n_bins': wg_nbins, 'q_low':wg_qlow, 'q_high':wg_qhigh})\n",
    "display(ui2)\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in df.columns.tolist() if 'its' in c.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plt.rcParams['figure.max_open_warning'] = 150\n",
    "\n",
    "# quantiles = [0.05, 0.95]\n",
    "# n_bins = 25\n",
    "\n",
    "\n",
    "\n",
    "# for var in df.columns:\n",
    "#     print(var)\n",
    "#     if var == 'bad': continue\n",
    "#     if not isinstance(df[var][0], (float, int, np.int64, np.float64)): continue\n",
    "#     var_good = df.query('bad==0')[var].tolist()\n",
    "#     var_bad  = df.query('bad==1')[var].tolist()\n",
    "#     print('plot')\n",
    "    \n",
    "#     plt.figure()\n",
    "#     fig, axes = plt.subplots(1,3, figsize=(18,5))\n",
    "#     for i in range(3):\n",
    "#         qs = [0,1] if not i else quantiles\n",
    "#         quantile_vals = np.quantile(var_good+var_bad, qs)\n",
    "#         _, bins = np.histogram(var_good + var_bad, bins=n_bins, range=quantile_vals)\n",
    "#         normed = (i == 2)\n",
    "#         axes[i].hist(var_good, bins=bins, alpha=1, color='blue', linewidth=1.2, histtype='step', linestyle='-', density=normed)\n",
    "#         axes[i].hist(var_bad, bins=bins, alpha=1, edgecolor='red', linewidth=2, histtype='step', density=normed)\n",
    "        \n",
    "        \n",
    "#     for qv in quantile_vals: axes[0].axvline(qv, linestyle='--', color='k')\n",
    "#     axes[0].set_title('whole range')\n",
    "#     axes[1].set_title(f'limited range (q={quantiles[0]*100:.0f},{quantiles[1]*100:.0f}): {quantile_vals[0]:.3f}, {quantile_vals[1]:.3f}')\n",
    "#     axes[2].set_title('normalized')\n",
    "        \n",
    "#     plt.suptitle(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "colors = ['#F53E22', '#3E22F5']\n",
    "pal = sns.color_palette(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df.std()[(df.std() < 1e-6).tolist()]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()\n",
    "nonphysical_cols = ['run', 'chunkID', 'time', \n",
    "                   'year', 'period.fString', 'pass.fString', 'runType.fString', \n",
    "                   'startTimeGRP', 'stopTimeGRP', 'duration', \n",
    "                   'chunkStart', 'chunkMean', 'chunkMedian', 'chunkRMS']\n",
    "\n",
    "no_variance_cols = df.std()[(df.std() < 1e-6).tolist()].index.tolist()\n",
    "cols_exclude_corr = nonphysical_cols + no_variance_cols\n",
    "\n",
    "for c in df.columns:\n",
    "    if c not in cols_exclude_corr:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corr matrix for all variables\n",
    "\n",
    "unreadable, but plenty of very strong correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df[[c for c in df.columns if c not in cols_exclude_corr]].corr()\n",
    "fig = plt.figure(figsize=(26,20))\n",
    "ax = fig.add_subplot(111)\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns,\n",
    "        cbar=1, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation distribution and most correlated pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = corr.abs().unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False)\n",
    "n_vars = df.shape[1]\n",
    "print('Most correlated pairs:\\n---------------\\n', \n",
    "      so[n_vars:n_vars+20]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "THRESHOLD = 0.9\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.hist(so, histtype='step', bins=100);\n",
    "plt.title('histo of corr. coef.');\n",
    "ylim = plt.ylim()\n",
    "y_l = ylim[0] + ylim[1]*0.15\n",
    "y_h = ylim[0] + ylim[1]*0.4\n",
    "arrow = mpatches.FancyArrowPatch((THRESHOLD, y_h), (THRESHOLD, y_l),\n",
    "                                 mutation_scale=25, color='red', \n",
    "                                 arrowstyle='fancy');\n",
    "ax.add_patch(arrow);\n",
    "ax.text(THRESHOLD-0.03, y_h, f'{THRESHOLD}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns with corr. over threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = corr.columns.tolist()\n",
    "# corr = corr.abs()\n",
    "\n",
    "for c1 in corr.columns:\n",
    "    for c2 in corr.columns:\n",
    "        if corr.columns.tolist().index(c1) <= corr.columns.tolist().index(c2): continue\n",
    "        cval = corr.abs()[c1][c2]\n",
    "        if cval > THRESHOLD and  c1 in cols_no_corr and c2 in cols_no_corr:\n",
    "            cols_no_corr.remove(c2)\n",
    "            print(f'{c2} removed due to its corr. with {c1} = {cval:.3f}')\n",
    "print('\\n\\n', cols_no_corr)\n",
    "print(f'\\n{len(cols_no_corr)} out of {len(corr.columns)} columns were selected')\n",
    "\n",
    "# pd.DataFrame(df.corr()['offsetdZCchi2Neg']).query('offsetdZCchi2Neg > 0.999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_sel = df[cols_no_corr].corr()\n",
    "\n",
    "fig = plt.figure(figsize=(18,15))\n",
    "ax = fig.add_subplot(111)\n",
    "sns.heatmap(corr_sel, \n",
    "        xticklabels=corr_sel.columns,\n",
    "        yticklabels=corr_sel.columns,\n",
    "        cbar=1, cmap='RdBu', \n",
    "        vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_top = so[256:266]\n",
    "print(so_top.index.levels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = 'meanTPCncl'\n",
    "var2 = 'rmsTPCncl'\n",
    "\n",
    "var1_vals = df[var1].tolist()\n",
    "var2_vals = df[var2].tolist()\n",
    "\n",
    "qs = [0.05, 0.9]\n",
    "q_vals1 = np.quantile(var1_vals, qs)\n",
    "q_vals2 = np.quantile(var2_vals, qs)\n",
    "\n",
    "quant_query = f'{var1}>{q_vals1[0]} & {var1}<{q_vals1[1]} & {var2}>{q_vals2[0]} & {var2}<{q_vals2[1]}'\n",
    "index_bad = df.query('bad==1 & ' + quant_query)\n",
    "index_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist2D(var1, var2, n_bins, q_low, q_high):\n",
    "    qs = [q_low, q_high]\n",
    "    \n",
    "    var1_vals = df[var1].tolist()\n",
    "    var2_vals = df[var2].tolist()\n",
    "    \n",
    "    var1_good = df.query('bad==0')[var1].tolist()\n",
    "    var1_bad  = df.query('bad==1')[var1].tolist()\n",
    "    var2_good = df.query('bad==0')[var2].tolist()\n",
    "    var2_bad  = df.query('bad==1')[var2].tolist()\n",
    "#     index_good = df.query('bad==0').index.to_list()\n",
    "#     index_bad  = df.query('bad==1').index.to_list()\n",
    "    \n",
    "    q_vals1 = np.quantile(var1_vals, qs)\n",
    "    q_vals2 = np.quantile(var2_vals, qs)\n",
    "    \n",
    "    quant_query = f'{var1}>{q_vals1[0]} & {var1}<{q_vals1[1]} & {var2}>{q_vals2[0]} & {var2}<{q_vals2[1]}'\n",
    "    index_good = df.query('bad==0 & ' + quant_query).index\n",
    "    index_bad  = df.query('bad==1 & ' + quant_query).index\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(df.loc[index_good][var1], df.loc[index_good][var2], color='b', facecolor='none')\n",
    "    plt.scatter(df.loc[index_bad][var1], df.loc[index_bad][var2], marker='x', color='r')\n",
    "    \n",
    "    xrange = q_vals1[1] - q_vals1[0]\n",
    "    yrange = q_vals2[1] - q_vals2[0]\n",
    "\n",
    "    plt.xlim([q_vals1[0]-0.1*xrange, q_vals1[1]+0.1*xrange])\n",
    "    plt.ylim([q_vals2[0]-0.1*yrange, q_vals2[1]+0.1*yrange])\n",
    "#     plt.ylim(q_vals2)\n",
    "#     plt.scatter(df.loc[index_bad][var1], df.loc[index_bad][var2], color='r', facecolor='none', lw=lw)\n",
    "#     fig, axes = plt.subplots(1,3, figsize=(18,5))\n",
    "#     for i in range(3):\n",
    "#         qs = [0,1] if not i else quantiles\n",
    "#         quantile_vals = np.quantile(var_good+var_bad, qs)\n",
    "#         _, bins = np.histogram(var_good + var_bad, bins=n_bins, range=quantile_vals)\n",
    "#         normed = (i == 2)\n",
    "#         axes[i].hist(var_good, bins=bins, alpha=1, color='blue', linewidth=1.2, histtype='step', linestyle='-', density=normed)\n",
    "#         axes[i].hist(var_bad, bins=bins, alpha=1, edgecolor='red', linewidth=2, histtype='step', density=normed)\n",
    "\n",
    "\n",
    "#         for qv in quantile_vals: \n",
    "#             axes[0].axvline(qv, linestyle='--', color='grey')\n",
    "# #             axes[0].text()\n",
    "#         axes[0].set_title('whole range')\n",
    "#         axes[1].set_title(f'limited range (q={quantiles[0]*100:.0f},{quantiles[1]*100:.0f}): {quantile_vals[0]:.3f}, {quantile_vals[1]:.3f}')\n",
    "#         axes[2].set_title('normalized per class')\n",
    "\n",
    "    plt.suptitle(var1+':'+var2)\n",
    "\n",
    "#w_nbins = interactive(lambda n: n, n=(3,100,1));\n",
    "#display(w_nbins)\n",
    "#print(w_nbins.kwargs)\n",
    "#w_varname.observe(update_x_range, 'value')\n",
    "\n",
    "# plt.text?\n",
    "\n",
    "wg_colname1 = widgets.Dropdown(description='column name 1', options=df.columns)\n",
    "wg_colname2 = widgets.Dropdown(description='column name 2', options=df.columns)\n",
    "# wg_nbins = widgets.IntSlider(description='n bins', min=3, max=100, value=20, step=1, continuous_update=False)\n",
    "wg_qlow = widgets.FloatSlider(description='lower quantile', min=0, max=0.3, value=0.0, step=0.01, continuous_update=False)\n",
    "wg_qhigh = widgets.FloatSlider(description='upper quantile', min=0.7, max=1, value=1, step=0.01, continuous_update=False)\n",
    "\n",
    "def make_plot(name, n_bins):\n",
    "    print('making plot of {} with {} bins'.format(name, n_bins))\n",
    "ui_cols = widgets.HBox([wg_colname1, wg_colname2])\n",
    "ui_quantiles = widgets.HBox([wg_qlow, wg_qhigh])\n",
    "# ui_bins = widgets.HBox([wg_nbins])\n",
    "\n",
    "out = widgets.interactive_output(plot_hist2D, {'var1': wg_colname1, 'var2':wg_colname2, 'n_bins': wg_nbins, 'q_low':wg_qlow, 'q_high':wg_qhigh})\n",
    "display(ui_quantiles)\n",
    "display(ui_cols, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in df_orig.columns if 'Warning' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xrun in list(set(df_orig['run'].tolist())):\n",
    "#     print(f'\\n *** {xrun} ***')\n",
    "    aver = np.mean(df_orig.query('run == @xrun')['alias_tpcItsMatchHighPtA_Warning'])\n",
    "    if aver > 0 and aver < 1: suffix = '\\t<---------'\n",
    "    else: suffix = ''\n",
    "    print(f'\\n {xrun} -- {aver} {suffix}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
